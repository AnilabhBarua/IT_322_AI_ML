#play with sD

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Set random seed for reproducibility
np.random.seed(42)

# Generate three datasets with different standard deviations
sample_size = 10
data1 = np.random.normal(0, 1, sample_size)    # Standard deviation = 1
print(data1)
print("****************************")
data2 = np.random.normal(0, 2, sample_size)    # Standard deviation = 2
print(data2)
print("****************************")
data3 = np.random.normal(0, 0.5, sample_size)  # Standard deviation = 0.5
print(data3)

# Calculate actual standard deviations
std1 = np.std(data1)
std2 = np.std(data2)
std3 = np.std(data3)

# Set up the plot
plt.figure(figsize=(12, 8))

# Plot histograms and density curves
plt.subplot(3, 1, 1)
sns.histplot(data1, kde=True, stat="density", color="blue")
plt.title(f"Gaussian Distribution with σ=1 (Calculated: {std1:.4f})")
plt.xlim(-8, 8)

plt.subplot(3, 1, 2)
sns.histplot(data2, kde=True, stat="density", color="red")
plt.title(f"Gaussian Distribution with σ=2 (Calculated: {std2:.4f})")
plt.xlim(-8, 8)

plt.subplot(3, 1, 3)
sns.histplot(data3, kde=True, stat="density", color="green")
plt.title(f"Gaussian Distribution with σ=0.5 (Calculated: {std3:.4f})")
plt.xlim(-8, 8)

plt.tight_layout()
plt.show()

# Show impact on machine learning using a simple example
X = np.linspace(-5, 5, 100).reshape(-1, 1)

# Compare probability densities
pdf1 = stats.norm(0, 1).pdf(X)
pdf2 = stats.norm(0, 2).pdf(X)
pdf3 = stats.norm(0, 0.5).pdf(X)

plt.figure(figsize=(10, 6))
plt.plot(X, pdf1, 'b-', label=f'σ=1')
plt.plot(X, pdf2, 'r-', label=f'σ=2')
plt.plot(X, pdf3, 'g-', label=f'σ=0.5')
plt.legend()
plt.title("Impact of Standard Deviation on Decision Boundaries")
plt.xlabel("Feature Value")
plt.ylabel("Probability Density")
plt.grid(True)
plt.show()

/////////////////////////////////////////////////////////////////////////////

activation funtion shape.ipynb
import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(-10, 10, 100)
sigmoid = 1 / (1 + np.exp(-x))

plt.plot(x, sigmoid)
plt.title('Sigmoid Activation Function')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.show()


tanh = np.tanh(x)

plt.plot(x, tanh)
plt.title('Tanh Activation Function')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.show()

relu = np.maximum(0, x)

plt.plot(x, relu)
plt.title('ReLU Activation Function')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.show()


///////////////////////////////////////////////////////////////////////////
various pd

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm, binom, poisson, bernoulli, beta, uniform

x_norm = np.linspace(-4, 4, 1000)
x_binom = np.arange(0, 21)
x_poisson = np.arange(0, 16)
x_bernoulli = [0, 1]


plt.figure(figsize=(15, 12))

# Normal (Gaussian) Distribution
plt.subplot(2, 3, 1)
mu, sigma = 0, 1
plt.plot(x_norm, norm.pdf(x_norm, mu, sigma), label=f'μ={mu}, σ={sigma}')
plt.title("Normal (Gaussian) Distribution")
plt.xlabel("x")
plt.ylabel("Probability Density")
plt.legend()

# Binomial Distribution
plt.subplot(2, 3, 2)
n, p = 20, 0.6
plt.vlines(x_binom, 0, binom.pmf(x_binom, n, p), colors='b', lw=5, alpha=0.6, label=f'n={n}, p={p}')
plt.title("Binomial Distribution")
plt.xlabel("Number of Successes")
plt.ylabel("Probability")
plt.legend()

# Poisson Distribution
plt.subplot(2, 3, 3)
lam = 5
plt.vlines(x_poisson, 0, poisson.pmf(x_poisson, lam), colors='g', lw=5, alpha=0.6, label=f'λ={lam}')
plt.title("Poisson Distribution")
plt.xlabel("Number of Events")
plt.ylabel("Probability")
plt.legend()

# Bernoulli Distribution
plt.subplot(2, 3, 4)
p_bernoulli = 0.8
plt.bar(x_bernoulli, bernoulli.pmf(x_bernoulli, p_bernoulli), color='orange', width=0.3, label=f'p={p_bernoulli}')
plt.xticks([0,1])
plt.title("Bernoulli Distribution")
plt.xlabel("Outcome")
plt.ylabel("Probability")
plt.legend()



